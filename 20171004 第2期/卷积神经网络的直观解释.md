# 	卷积神经网络的直观解释

###         什么是卷积神经网络以及为什么它那么重要？

卷积神经网络（ConvNets 或者 CNNs）是一种神经网络。它在许多领域都有起了很好的作用，比如图片的识别和分类。卷积神经网络已经成功的应用在了机器人视觉和自动驾驶骑车的人脸识别、物体识别以及交通标志识别方面。

![图1](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2017-05-28-at-11-41-55-pm.png?w=1024)

在图1中，卷积神经网络能够识别屏幕上的信息，并能给出图片内容相对应的字幕（“一个足球运动员在射门。”）。图2中可以看到卷积网络被用于识别日常物品、人、动物的实例。最近，卷积神经网络在一些自然语言处理问题（比如句子分类）也十分有效。

![图2](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-4-17-11-pm.png?w=1024)

由此可见，在如今，卷积神经网络是机器学习从业者十分重要的工具。然而，对于初学者来说，理解并使用卷积神经网络是一个十分不容易的经历。这篇博客发出来最初的目的就是去让人更好的理解卷积神经网络在处理图像方面的工作。

一般来说，如果你是第一此接触神经网络的话，我推荐你去看看[这篇文章（关于多层感知层）](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)在深入之前先去了解一下关于神经网络工作的原理。多层感知器在本文中称为“完全连接的层”。

#### LeNet架构（1990年代）

LeNet是最早的卷积神经网络之一，它帮助推进了深度学习的进程。自1988年以来的一些成功的迭代后，这个开拓性的工作被命名为LeNet5。在那个时候LeNet架构主要被用于字符识别任务比如阅读打包的代码、数字等。

下面，我们会使大家直观的了解到LeNet架构如何学会辨认图片。近几年有一些新的在LeNet架构基础上强化了的架构出现，但是它们都运用了LeNet架构的主要思想，所以如果你对于LeNet有一个清晰的理解这回使你更容易了解近几年出现的那些相关的架构。

![图三](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-4-59-29-pm.png?w=1024)

图三所示的卷积神经网络在架构上相似于最初的LeNet，将输入的一张图片内容分出四个种类的可能性：狗、猫、船和鸟（最初的LeNet主要就是被用于字符识别任务）。图中很明显，将船作为该图片识别的结果输出，神经网络在四种可能性中正确的判断出船的可能性最高（94%）。输出端所有的可能性的总和应为1。（这一点在本文的后面会解释。）

在图三所示的神经网络中有四点主要的操作：

1.卷积

2.非线性

3.池化

4.分类

这些选项是构造一个卷积神经网络的基本模块，所以理解这些都是模块是如何工作，这是提高对卷积神经网络的理解很重要的一步。我们接下来将试着对于这些部分的工作原理有个直观的理解。

#### 一张图片是一个像素值矩阵

本质上说，每一张图片都可以用一个像素值矩阵表示。

![动图1](https://ujwlkarn.files.wordpress.com/2016/08/8-gif.gif?w=192&h=192&zoom=2)

通道是一个用来描述一张图片的某一确切部分的常规术语。一张图片在一个标准的数字相机中会有三个通道-红，绿和蓝-你可以把这个想象成3个2d的矩阵彼此堆叠形成（每个都代表各自的颜色。）每个矩阵有像素值大小范围为0到255。

一个灰度级图形，从另一个方面说，它就只有一个通道。为了这个文章的目的，我们将只考虑灰度级图形，所以我们会将每个单独的2d矩阵代表一个图片。在矩阵中每个像素值得范围都是从0-255。--0表示为黑色，255表示为白色。

#### 卷积步骤

卷积神经网络它的名字的由来就是它的“卷积”操作。卷积操作的主要目的就是为了从输入的图形中选取特征。卷积通过使用输入数据的小正方形去学习图形的特征以此保证了像素之间的空间关系不变。我们在此不深入探究卷积内部的数学方面的细节，但是我们将试着通过图片了解它的工作。

正如我们先前讨论的一样，每一个图片可以被当成一个像素值矩阵考虑。想象一个5×5的图片，它的像素值只有0和1两个值表示。（我们知道一个灰度级图片，像素值范围为从0到255，下图绿色的矩阵是一个像素值只有0和1两个值的情况）：

![图](https://ujwlkarn.files.wordpress.com/2016/07/screen-shot-2016-07-24-at-11-25-13-pm.png?w=150&h=136)



同时，考虑一个3×3的矩阵如下所示：

![](https://ujwlkarn.files.wordpress.com/2016/07/screen-shot-2016-07-24-at-11-25-24-pm.png?w=74&h=64)

然后，对于5×5的图片用3×3的矩阵进行卷积处理计算。如下图5所示。

![图5](https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=268&h=196&zoom=2)

这需要花一点时间去理解上图的计算是如何完成的。我们通过橙色的矩阵在我们的初始绿色矩阵上逐步滑动依次处理，我们使用矩阵乘法的运算计算选中的元素并将计算结果记录，最后计算结果形成了图中粉色的矩阵部分所示。这种3×3的最终看到的结果矩阵只是输入图片的一个像素点的处理结果。

用卷积神经网络的专业中，上图橙色的3×3矩阵被叫做一个“过滤”或者""或者“特征检测器”，通过逐步滑动处理得到的矩阵被称为“卷积的特征”或者“激活图”又或者叫“特征图”。记住特征图是从最初始的输入图片过滤而来的，这一点是十分重要的。

很显然从上面的动图看一看出不同的过滤矩阵会导致同一张输入图片生成不同的特征图。举个例子，将下方的图片当作输入图片：

![输入图片](https://ujwlkarn.files.wordpress.com/2016/08/111.png?w=67&h=66)

如下面的表格所示，我们可以看到不同的过滤器对于同一张输入图片的不同结果。我们可以通过改变过滤器的值进行Edge detection、Sharpen、Blur等不同的操作。这意味着不同的过滤器可以发现同一张图片的不同特征，比如edges,curves等。更多的例子可以在[这个链接]()查看。

![表格](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-05-at-11-03-00-pm.png?w=342&h=562)

另一个理解卷积操作的好方法就可以看下图六的动图。

![动图2](https://ujwlkarn.files.wordpress.com/2016/08/giphy.gif?w=480&zoom=2)

一个过滤器（红色的框表示）依次滑过输入图片（进行卷积操作）后得到一个特征图。另一个过滤器（绿色的框表示）依次滑过同一个输入图片后我们可以看到得出一个不同的特征图。这里要注意这两个不同的特征图是同一个图片过滤处理得到的。记住这个图片和两个过滤器本质上就是我们上文提到的数字矩阵。

在实践中，一个神经网络在训练过程中靠自己计算得到过滤器的数字矩阵。（虽然在训练开始前，我们仍然需要去指定部分参数，比如过滤器的数量、过滤器的大小、神经网络的结构层次等）我们使用更多的过滤器的话，我们就可以提取到更多的图像特征，那么我们的神经网络在辨认它没有学习过的图片时，就会有更好的表现。

特征图的大小被三个方面控制着，这三个方面需要我们在卷积步骤之前下好决定。

- 深度：深度对应于卷积操作中过滤器的数目。在图7所示的神经网络中，我们可以看到，使用了三个不同的过滤器处理同一张船的图片，可以看到得到了三个不同的特征图。你可以将这三个特征图看作堆在一起的2d矩阵，所以，特征图的深度就是三。

  ![图7](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-10-at-3-42-35-am.png?w=401&h=201)

- 步幅：步幅是我们在用过滤器矩阵在输入矩阵上滑动时每一步滑过的像素的数量。当步幅为1时我们每次将过滤器移动一个像素。当步幅为2时，过滤器在滑行时每次移动两个像素。用更大的步调将会生成更小的特征图。

- 零填充：有时候，将输入矩阵的边界用0填充是十分便捷的，这样我们就可以将过滤器应用于输入矩阵的边界区域了。一个好的零填充特征是我们能通过它去控制特征图的大小。添加零填充也被叫做宽卷积，不使用零填充就是一个窄卷积。这已经被很清楚的解释了[14]。

#### 介绍非线性（ReLU）

在每次卷积操作后有一个被称为ReLU的额外操作，如图8所示。ReLU代表纠正线性部分，是一个非线性操作。它的输出公式如下：

![图8](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-10-at-2-23-48-am.png?w=768&h=241)

ReLU是一个单元操作（应用于每个像素点）并用0代替特征图中的所有负数。在我们的卷积网络中使用ReLU的目的是为了有一个非线性操作，因为我们想要我们的卷积网络学习的现实数据时具备处理非线性的情况。（卷积是一个线性的操作—— 元素矩阵对于的乘法和加法，所以我们引用ReLU函数这样的非线性函数来解释非线性情况。）

ReLU操作可以在图9中得到很清晰的理解。图9中可以看出将ReLU操作对图6所示的特征图中的一个进行处理后的结果。这里输出的特征图也可以称为“整流”特征图。

![图9](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-6-18-19-pm.png?w=1024)

别的非线性函数比如tanh和sigmoid函数都可以用来代替ReLU,但是ReLU被发现在很多的情况下表现的更好。

#### 池化步骤

空间的池化（也被称为二次采用或下采用）在减少了每个特征图的维度的同时，保留了最重要的信息。空间的池化是与求最大值、求平均数、求和等之外一种不同的类别。

在最大池化的条件下，我们定义一个空间邻域（举个例子，一个2*2的网格），取出空间特征图的最大元素填入网格中。我们也可以不取最大元素，可以取所有元素的平均数或取所有元素的和填网格中。在实践中发现，最大值的池化的效果更好。

图10展示了一个使用2*2网格在空间特征图(经过了卷积操作和ReLU操作)中求最大值池化的例子。

![图10](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-10-at-3-38-39-am.png?w=768)

我们以2个步调滑动2*2的网格并求取每个区域中的最大值。正如图10所示，这减少了特征图的维度。

在图11所示的神经网络中可以看出，池化操作分别应用于每个特征图。（注意，正因为如此，我们可以从三个输入图中得到三个输出图。）

![图11](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-6-19-37-pm.png?w=401&h=219)

图12可以看出池化应用于图9所示的空间特征图后的结果。

![图12](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-6-11-53-pm.png?w=1024)

池化的方法逐步的减少了输入表现的空间大小。尤其是，池化

- 使得输入的表现（特征维数）更小并且更好控制。

- 减少了神经网络中参数和计算的数量，因此，避免了过拟合

- 使得神经网络中的不变量变成可进行改变的，输入图形中的失真和翻译。（一个在输入中的小的失真不会改变池化的结果—因为我们在一个邻域中取最大值/平均值作为我们的取值。）

- 帮助我们获得几乎不变的图像（精确项是”等方差“。）这是十分重要的，因为我们可以以此判断出一张图片中的物体，无论它在图片的什么地方。（查看更多细节）

  #### 到此为止

  ![图13](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-08-at-2-26-09-am.png?w=1024)

目前为止，我们已经知道了卷积、ReLU、池化它们都是如何进行操作的。理解任何卷积神经网络的这些基本组成部分这是十分重要的。正如图13所示，我们有两个卷积层、两个ReLU和池化的层—第二次卷积在第一次卷积结果的基础上使用了六个过滤器，最后得到了六个特征图。ReLU又一次运用在这六个特征图中。接着我们在这6个特征图上分别进行最大值池化操作。

这些所有操作抽取出了图片中有用的信息，在我们的神经网络中使用非线性，在使特征不同于模型和翻译的时候减少特征维度。

第二次池化层后的输出在全连接层中做为输入，全连接层我们将在下面介绍到。

#### 全连接层

全连接层是一种传统的多层感知器，它在输出层种使用了一个softmax激活函数（其他传统的如SVM(支持向量机)也可以使用，但是在本文中以softmax（归一化指数函数）作为例子。）术语”全连接“意思是在前一层的每一个神经元都与下一层的每一个神经元相连接。如果你对于多层感知器不是很了解的话，我推荐你取阅读[这篇文章](https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/)。

输入的图片经过卷积层和池化层处理后的结果代表了图片的显著特征。全连接层的目的是使用这些显著特征在训练集的基础上，将输入图片分为不同的类。举个例子，一个图片分类任务如下图14所示分类得到了4个可能的输出。（注意，图14没有展示出全连接层的结点之间的连接。）

![图14](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-06-at-12-34-02-am.png?w=768&h=241)

除了分类，增加一个全连接层也经常是一种更为便宜的学习到这些特征的非线性结合。从卷积层和池化层得到的大多数特征对于分类任务都十分方便。但是全连接层会将这些特征结合的更好。

从全连接层处理后的输出结果可能只有一个。这可以通过使用Softmax函数在全连接层的输出层作为激活函数实现。Softmax函数可以将数据进行归一化处理，即将任意大小的数值全转化为0到1范围内的数。

#### 将所有的放到一起 — 反向传播训练

正如上文所提到的，卷积层和池化层就像是输入图片的特征提取器，而全连接层就像是一个分类器。

注意下面的图15，因为输入的图片是一艘船，所以计算结果船类的可能性为1，而其他三类的可能性为0

- 输入图片 = 船
- 结果向量 = [0,0,1,0]

![图15](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-9-15-21-pm.png?w=1024)

卷积神经网络的训练过程可以总结为下述几个步骤：

- 第一步：我们分析所有的过滤器和参数/任意值的权重。

- 第二步：神经网络是将一张图片作为输入，接着通过下面的步骤（卷积，ReLU和池化操作以及在全连接层的操作）最后得到的输出结果为一个类。

  - 比如船的图片的输出的结果可能性结果可能为[0.2,0.4,0.1,0.3]
  - 因为权重在第一次训练的例子中是随意设置的，所以输出结果也同样是随意的。

- 第三步：计算输出层的总错误（将4种可能相加）。

  - 总错误 = **∑  ½ (target probability – output probability) ²** 

- 第四步：利用反向传播去计算神经网络中所有权重的误差梯度，再用梯度下降的方法去更新所有过滤器中各个值和常量值以此达到降低输出错误率的目的。

  - 权重值根据各部分对于最后的总错误的影响大小进行调整。
  - 当以同一幅图片在此输入当输入值的话，输出结果可能为[0.1,0.1,0.7,0.1],这与目标向量[0,0,1,0]十分相近。
  - 这意味着神经网络学习更好的正确的分类这些特定的图片的方式是通过错误输出不断调整各个权重的值。

- 第五步：将训练集中的图片都进行2-4步操作。

  上述的步骤训练了卷积神经网络—这基本上可以理解为卷积神经网络的所有权重和参数通过分类训练集的图片得到了优化。

  当一张新得图片作为输入值放入卷积神经网络中，神经网络将通过上述得几个不走最后得到每个类型得可能性。（对于一张新的图片来说，会代入经过训练集优化后的权值参数参与运算，计算输出中每个种类的可能性。）如果我们的训练集足够大，神经网络将更有可能会将新图片归类的更好，得到正确的类别。

  注意1：上述步骤是简化的概况，其中的数学细节没有介绍，使得对于训练过程有个直观的了解。想知道其中更多的数学细节可以查看[这个](http://cs231n.github.io/convolutional-networks/)和[这个](http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/)。

  注意2：在上面举的神经网络的例子中，我们假设有两组卷积层和池化层。然而请注意，在一个卷积网络中这样的操作可以重复任意次数。事实上，如今很多效果好的卷积神经网络都有着几十层的卷积层和池化层！同样，一个卷积层后也并不是一定要有一个池化层的。在下图16可以看出，在一个池化操作前我们有着多层卷积层和ReLU操作。同时值得注意的是卷积网络的每一层是如何可视化的。在下图16可以看出。

  ![图16](https://ujwlkarn.files.wordpress.com/2016/08/car.png?w=768)

  #### 可视化卷积神经网络

  一般来说，我们使用越多的卷积步骤，我们的神经网络将有更完整的特征去识别。举个例子，一个卷积神经网络在分类图片时可能第一层可能时从原始像素中识别边缘，然后将第一层识别到的边缘去识别大致的形状，然后通过这些形状去识别更高急别的特征，比如在更高层识别面部形状。这一点可以在下图17得到论证 — 这些特征使用一个卷积深度信念网络，图片在这里只是想论证这样的一个想法。（这只是一个例子：现实生活中卷积的特征可能识别各种物体，不只是识别人）

  ![图17](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-10-at-12-58-30-pm.png?w=284&h=300)

Adam Harlay 基于训练MNIST数据库中的手写数字创造了一个神奇的卷积网络可视化。我强烈推荐大家可以[玩这个](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)去理解卷积网络工作的细节。

我们在下图中可以看到卷积神经网络如何处理输入的‘8’。注意在图18的可视化中没有把ReLU操作展示出来。

![图18](https://ujwlkarn.files.wordpress.com/2016/08/conv_all.png?w=1024)

输入的图片包含了1024个像素（32×32)，第一层卷积层（卷积层1）是由6个步同的5×5大小，步幅为1的过滤器对输入图片进行处理。正如所看到的，使用6个不同的过滤器得到的一个深度为6的特征图。

经过卷积层1处理之后就是池化层1，将卷积层1得到的6个特征图分别进行用2×2的网格进行最大值池化（步幅为2）。你可以移动你的鼠标点击池化层任何一个像素，观察2×2网格，它是由先前的卷积层的结果形成的。（图19可以证明）你可以注意到在2×2网格中最大的值（最亮的一个）会放入池化层。

![图19](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-06-at-12-45-35-pm.png?w=1024)

经过池化层1处理之后运行16个5×5（步调为1）的卷积操作的过滤器。接着是池化层2，它做2×2的最大池化（步调为2）。这两层与上面的概念相同。

然后我们会有3个全连接层。它们为：

- 第一层有120个神经元
- 第二层有100个神经元
- 第三层有10个神经元对应着10个数字—也可以称为输出层

注意在图20中，输出层的10个结点都与第二个全连接层的100个结点相连接。（因此称为全连接）

同时，注意在输出层只有一个亮的结点对于为‘8’。—这意味着神经网络正确的将我们的手写数字分类了。（亮结点表示输出结果它的值最高。即识别手写数字时，在输出结果各个数字的可能性中，8是所有数字中可能性最高的。）

![图20](https://ujwlkarn.files.wordpress.com/2016/08/final.png?w=1024)

同样的可视化的3d版本可以在[这里](http://scs.ryerson.ca/~aharley/vis/conv/)查看。

#### 别的卷积神经网络架构

卷积神经网络在20世纪90年代早期就出现了。我们在前文中介绍了最早的卷积神经网络之一的LeNET。还有一些别的有影响力的架构我列在下面。

- LeNET(1990s):这篇文章已经介绍了。
- 1990s 到 2012：在20世纪90年代末期到2010年早期，卷积神经网络正在酝酿中。随着越来越多的数据和计算能力变得可用，卷积神经网络能够处理的任务也越来越有趣了。
- AlexNet(2012):在2012年，Alex Krizhevsky （和一些人）发布了[AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)，它是一个比LeNET更深刻，更广泛的版本。它赢了2012年的一个全球最权威的计算机视觉竞赛（LISVRC）。与以前的方法相比，它是一个显著的突破，现如今卷积神经网络有着广泛的应用也得益于这个工作。
- ZF Net(2014):2013 年ILSVRC竞赛的胜者是一个来自Matthew Zeiler 和Rob Fergus 的卷积神经网络。它被称[ZFNet](http://arxiv.org/abs/1311.2901)。它在AlexNET的前提上在调整构架参数，使神经网络得到优化。
- GoogLeNET(2014):2014年ILSVRC的胜者是[SZEGEDE等人](http://arxiv.org/abs/1409.4842)的卷积神经网络，来自谷歌。它的主要贡献是开发了一个初始模块，该模块极大地减少了网络中参数的数量，（它只有4M，而AlexNet有60M.）
- VGGNet(2014):2014年ILSVRC竞赛中的亚军被称为[VGGNeT](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)。它的主要贡献是在神经网络的深度（层数）方面有个获得获得良好表现的重要组件。
- ResNets(2015):[Residual Network](http://arxiv.org/abs/1512.03385)由Kaiming He(和一些人)一起开发而来，它是2015年ILSVRC竞赛的冠军。ResNets是目前为止最先进的卷积神经网络模型，并且是在实践中使用卷积神经网络的默认选择。（截止2016年5月）
- DenseNet(2016年8月）：最近由黄高（和一些人）一起发布的密集连接的卷积神经网络。它任意两层之间都有之间的连接。在五个高度竞争的对象识别基准任务中，它已经显示出与以往最先进的体系结构的优势。查看[相关更多](https://github.com/liuzhuang13/DenseNet)

#### 结论

在本文中，我已经试着用简单的表达去解释卷积神经网络的主要概念。这其中有几个细节我已经简化/跳过了，但我希望这篇文章能让你直观的了解到卷积神经网络是如何工作的。

这篇文章的灵感来自于Denny Britz 的 《[理解NLP的卷积神经网络](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)》(我十分推荐阅读)，本文的一些解释都是基于这篇文章的。为了更全面的理解其中的一些概念，我鼓励你通过一些Stanford大学与卷积神经网络有关课程的笔记以及下面参考中所提到的资源。如果你遇到任何问题，对上述任何概念由疑问，随时在下方留言。

文章中所有的图片和动图属于它们的各自的作者，如下面的参考部分所列。

#### 参考：

1.

1. [karpathy/neuraltalk2](https://github.com/karpathy/neuraltalk2): Efficient Image Captioning code in Torch, [Examples](http://cs.stanford.edu/people/karpathy/neuraltalk2/demo.html)
2. Shaoqing Ren, *et al,* “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks”, 2015, [arXiv:1506.01497 ](http://arxiv.org/pdf/1506.01497v3.pdf)
3. [Neural Network Architectures](https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba), Eugenio Culurciello’s blog
4. [CS231n Convolutional Neural Networks for Visual Recognition, Stanford](http://cs231n.github.io/convolutional-networks/)
5. [Clarifai / Technology](https://www.clarifai.com/technology)
6. [Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.2gfx5zcw3)
7. [Feature extraction using convolution, Stanford](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)
8. [Wikipedia article on Kernel (image processing) ](https://en.wikipedia.org/wiki/Kernel_(image_processing))
9. [Deep Learning Methods for Vision, CVPR 2012 Tutorial ](http://cs.nyu.edu/~fergus/tutorials/deep_learning_cvpr12)
10. [Neural Networks by Rob Fergus, Machine Learning Summer School 2015](http://mlss.tuebingen.mpg.de/2015/slides/fergus/Fergus_1.pdf)
11. [What do the fully connected layers do in CNNs? ](http://stats.stackexchange.com/a/182122/53914)
12. [Convolutional Neural Networks, Andrew Gibiansky ](http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/)
13. A. W. Harley, “An Interactive Node-Link Visualization of Convolutional Neural Networks,” in ISVC, pages 867-877, 2015 ([link](http://scs.ryerson.ca/~aharley/vis/harley_vis_isvc15.pdf)). [Demo](http://scs.ryerson.ca/~aharley/vis/conv/flat.html)
14. [Understanding Convolutional Neural Networks for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)
15. [Backpropagation in Convolutional Neural Networks](http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/)
16. [A Beginner’s Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/)
17. Vincent Dumoulin, *et al*, “A guide to convolution arithmetic for deep learning”, 2015, [arXiv:1603.07285](http://arxiv.org/pdf/1603.07285v1.pdf)
18. [What is the difference between deep learning and usual machine learning?](https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md)
19. [How is a convolutional neural network able to learn invariant features?](https://www.quora.com/How-is-a-convolutional-neural-network-able-to-learn-invariant-features)
20. [A Taxonomy of Deep Convolutional Neural Nets for Computer Vision](http://journal.frontiersin.org/article/10.3389/frobt.2015.00036/full)
21. Honglak Lee, *et al*, “Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations” ([link](http://web.eecs.umich.edu/~honglak/icml09-ConvolutionalDeepBeliefNetworks.pdf))