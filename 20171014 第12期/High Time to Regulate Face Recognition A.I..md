# High Time to Regulate Face Recognition A.I.

原文链接：[High Time to Regulate Face Recognition A.I.](https://medium.com/intuitionmachine/high-time-to-begin-regulation-of-face-recognition-a-i-f4a92ee40165?from=hackcv&hmsr=hackcv.com)

We’ve reached a tipping point where it is now high time that we start the conversation of regulating Face Recognition Artificial Intelligence (AI).

In a [previous post](https://medium.com/intuitionmachine/how-to-regulate-artificial-intelligence-10725701043b), I explored some ideas of how we may regulate AI. I looked at several regulations in other fields and explored how they might apply for AI. The most compelling argument against AI regulation has been that it isn’t clear for many as to precisely what needs to be regulated. However, in recent days, it has come to my attention that a specific kind of AI algorithm needs serious thought for regulation.

[Stanford researchers](https://osf.io/zn79k/) have trained a Deep Learning system to recognize a person’s sexual orientation. I don’t doubt the effectiveness of the system that they’ve built. Many however questioned the interpretations of the researchers. I am however very concerned of the potential for misuse of this kind of technology.



![img](https://cdn-images-1.medium.com/max/800/1*5VhzZSfzf-ETGjy7fx-abQ.jpeg)

Source: [Deep neural networks are more accurate than humans at detecting sexual orientation from facial images.](https://osf.io/zn79k/)

In May this year, Chinese researchers developed an even more dubious face classification system that determined if someone was likely to be a criminal or not.



![img](https://cdn-images-1.medium.com/max/800/1*EEhfnjTH_nNHDwiXwwby8g.jpeg)

Paper: [Automated Inference on Criminality using Face Images](https://arxiv.org/pdf/1611.04135.pdf)

We now urgently need to analyze the benefits of facial recognition against the risks. I am going to take a stab at this and will eventually make the argument that the risks outweigh the benefits.

Here are some of the benefits of facial recognition:

**Security** — Facial recognition is now built into the iPhone X (see: [Face ID](https://www.wired.com/story/iphone-x-faceid-security/)) and is used as an authentication mechanism to unlock one’s phone. Previously, the iPhone (an other smart phones) used one’s fingerprint for unlocking a device. Facial recognition can also be used for monitoring people visiting homes or offices.

**Social Engagement** — Facebook can automatically tag faces found in photographs. The value of this feature is to increase engagement by people who are tagged as well as from people who follow other people. Facebook has added additional security features that allows a user to opt-out of the automatic face tagging feature.

**Safety**- In car face monitoring devices can determine if a driver is distracted momentarily. This application can be employed in any work related activity that requires focused attention by the employed worker.

**Healthcare** — Monitoring devices for people who are sick or disabled may be useful in providing more responsive care to their needs.

**Entertainment** — Virtual Reality or Augmented Reality games may react to the emotions of its participants.

**Productivity** — Face recognition is used by Google Photos to automatically organize and search one’s own personal photos.

**Law Enforcement** — Face recognition can be used to identify suspects in a criminal investigation. This can also be used to track and find missing persons.

Here are the potential risks:

**Police State** — Facial recognition allows states to track the movement and behavior of its citizens. This allows the states to enforce compliance to its agenda.

**Biological Identification** — Facial recognition may recognize a person’s sexual orientation. In many countries, one’s sexual orientation is punishable as a crime. It may be debatable how accurate a system like this can become. However, if governments are satisfied with its accuracy, then people will be persecuted for being who they are and not what they had done. Recognizing a person’s heritage or race is another area where this can be abused.

**Behavioral Manipulation** — This involves the identification of a person facial responses in different contexts. Identification of reactions like disgust or awe may indicate to the observer the inner personal views of a person. Exploiting this information allows other parties (i.e. marketing, sales, government, employer etc.) to execute behavioral manipulation techniques that may be in conflict with a person’s well being. We have already been witness to these behavioral techniques in social networks to influence one’s actions.

**Behavioral Enforcement** — Workers can be monitored to asses their continued focus on a task at hand. Day dreaming will be penalized with wage garnishment.

I am going to stop here now with regards to the risks. There are many more risks that I am deliberately failing to mention here. One can even extrapolate far in the future and it is easy to envision a scenario that we would regret ever allow machines to recognize us.

However, what is the general overarching principle here why facial recognition is such a dangerous idea? The first problem is that because it is performed by automation, it can be done at scale and relentlessly. This leads to the same privacy concerns we have with large internet companies. The second concern is also that of privacy, that is, our inner thoughts and preferences should remain private. The third problem is the potential for summary judgement by a machine. It is all too easy for humans to lazily rely on an algorithm to perform judgement rather than to do so themselves. Furthermore, having an algorithm make judgement, in many ways washes one clean of any responsibility of the consequences. This judgement is made much worse when the criteria for judgement is based on how you look.

Photo copier machines are regulated from being able to copy and print legal paper currencies. The software in any printer is hardwired to detect specific signatures in money and thus preventing facsimile copy. Similarly, it may perhaps be possible to require that any new deep learning silicon (of sufficient performance) be required invalidate any facial recognition task. Alternatively, it should be illegal to hook up a deep learning device with a image capture system without the necessary ‘safeguard chip’ in place.

A lighter form of regulation should allow any person to opt-out from facial recognition. It could be implemented with the use of a kind of marker or code that is worn by the user (perhaps a barcode on the forehead?). This is analogous with the self-identification race forms found in the US. A person should, by law, be always allowed to opt-out from facial recognition software. The alternative will be a new kind of fashion:



![img](https://cdn-images-1.medium.com/max/800/1*r1N9X-eFEUDm2FSibwdJ3g.jpeg)

Source: <https://cvdazzle.com/#style-tips>

I am absolutely certain that many AI researchers will be up in arms with this proposal for regulation. However, you will need to be able to make the case that the benefits of facial recognition capabilities absolutely outweigh the risks. The risks are very real and it is about time that we begin serious discussion.

**Further Reading**

[**Facial recognition software is not ready for use by law enforcement**
*Recent news of Amazon's engagement with law enforcement to provide facial recognition surveillance (branded…*techcrunch.com](https://techcrunch.com/2018/06/25/facial-recognition-software-is-not-ready-for-use-by-law-enforcement/)



![img](https://cdn-images-1.medium.com/max/800/1*j9kar_3vwdJK8twhtmXC0g.png)

More coverage here: <https://gumroad.com/products/WRbUs>